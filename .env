PERSIST_DIRECTORY=db
MODEL_TYPE=LlamaCpp
MODEL_URL=https://huggingface.co/vicuna/ggml-vicuna-13b-1.1/resolve/main/ggml-vic13b-q8_0.bin
MODEL_PATH=models/ggml-vic13b-q8_0.bin
EMBEDDINGS_MODEL_NAME=all-MiniLM-L6-v2
MODEL_N_CTX=1000
TARGET_SOURCE_CHUNKS=4
N_GPU_LAYERS=7
USE_MLOCK=0

MODEL_N_BATCH=8
N_BATCH=1024

#MODEL_PATH=models/ggml-gpt4all-j-v1.3-groovy.bin
#MODEL_PATH=models/ggml-vicuna-13b-1.1-q4_2.bin
#MODEL_PATH=models/ggml-old-vic13b-q5_1.bin
